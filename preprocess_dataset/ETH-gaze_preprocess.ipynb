{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "IMAGE_FILES = []\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = '/xgaze_224/train/'\n",
    "\n",
    "save_folder_right = ''\n",
    "save_folder_left = ''\n",
    "save_csv_folder = ''\n",
    "\n",
    "os.makedirs(save_folder_right, exist_ok=True)\n",
    "os.makedirs(save_folder_left, exist_ok=True)\n",
    "os.makedirs(save_csv_folder, exist_ok=True)\n",
    "\n",
    "right_list = [7,33,112,130,133,144,155,153,154,157,158,159,160,160,161,162,163, 173]\n",
    "left_list = [249,255,341,359,382,373,374,380,381,381,384,385,386,387,388,390,398,466]\n",
    "# validation_subject = ['subject0010','subject0020','subject0030','subject0040','subject0050','subject0060','subject0070','subject0080','subject0090','subject0100','subject0110']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "from typing import List, Mapping, Optional, Tuple, Union\n",
    "landmark_pb2.NormalizedLandmarkList\n",
    "import numpy as np\n",
    "\n",
    "_PRESENCE_THRESHOLD = 0.5\n",
    "_VISIBILITY_THRESHOLD = 0.5\n",
    "_BGR_CHANNELS = 3\n",
    "\n",
    "ldmks_list = []\n",
    "\n",
    "\n",
    "def _normalized_to_pixel_coordinates(\n",
    "    normalized_x: float, normalized_y: float, image_width: int,\n",
    "    image_height: int) -> Union[None, Tuple[int, int]]:\n",
    "  \"\"\"Converts normalized value pair to pixel coordinates.\"\"\"\n",
    "\n",
    "  # Checks if the float value is between 0 and 1.\n",
    "  def is_valid_normalized_value(value: float) -> bool:\n",
    "    return (value > 0 or math.isclose(0, value)) and (value < 1 or\n",
    "                                                      math.isclose(1, value))\n",
    "\n",
    "  if not (is_valid_normalized_value(normalized_x) and\n",
    "          is_valid_normalized_value(normalized_y)):\n",
    "    # TODO: Draw coordinates even if it's outside of the image bounds.\n",
    "    return None\n",
    "  x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "  y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "  return x_px, y_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaze_calc_show(gaze_data):\n",
    "    global img_num\n",
    "    alpha = gaze_data[0]\n",
    "    beta = gaze_data[1]\n",
    "    gt_gaze_x = -1 * np.sin(beta) * np.cos(alpha)\n",
    "    gt_gaze_y = -1 * np.sin(alpha)\n",
    "    gt_gaze_z = -1 * np.cos(alpha) * np.cos(beta)\n",
    "    \n",
    "    return [gt_gaze_x, gt_gaze_y, gt_gaze_z]\n",
    "\n",
    "def gaze_calc(gaze_data, path):\n",
    "    global img_num\n",
    "    alpha = gaze_data[0]\n",
    "    beta = gaze_data[1]\n",
    "    gt_gaze_x = -1 * np.sin(beta) * np.cos(alpha)\n",
    "    gt_gaze_y = -1 * np.sin(alpha)\n",
    "    gt_gaze_z = -1 * np.cos(alpha) * np.cos(beta)\n",
    "    \n",
    "    return [path, gt_gaze_x, gt_gaze_y, gt_gaze_z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "def show_gaze_img(img, gaze):\n",
    "    x = int(img.shape[1]/2)\n",
    "    y = int(img.shape[0]/2)\n",
    "    img = cv2.circle(img, (x, y), 1, (0,0,255), thickness = 1)\n",
    "    img = cv2.arrowedLine(img, (x, y), (x + int(50*gaze[0]), y + int(50*gaze[1])), (255, 0, 0), thickness=1)\n",
    "    show_img(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = sorted(os.listdir(data_folder_path), key=lambda s: int(re.search(r'\\d+', s).group()))\n",
    "# print(subject_list)\n",
    "img_num = 1\n",
    "gaze_datas = []\n",
    "all_img_name_cnt = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_cropper(img, ldmk_x, ldmk_y):\n",
    "    if ldmk_y - 18 < 0:\n",
    "        movement_h = int(round(18 - ldmk_y, 0))\n",
    "    elif ldmk_y + 18 > img.shape[0]:\n",
    "        movement_h = int(img.shape[0] - (ldmk_y + 18))\n",
    "    else:\n",
    "        movement_h = 0\n",
    "\n",
    "    if ldmk_x - 30 < 0:\n",
    "        movement_w = int(round(30 - ldmk_x, 0))\n",
    "    elif ldmk_x + 30 > img.shape[1]:\n",
    "        movement_w = int(round(img.shape[1] - (ldmk_x + 30)))\n",
    "    else:\n",
    "        movement_w = 0\n",
    "    \n",
    "    return img[int(round(ldmk_y-18, 0)+movement_h):int(round(ldmk_y+18, 0)+movement_h), int(round(ldmk_x-30, 0))+movement_w:int(round(ldmk_x+30,0))+movement_w]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = sorted(subject_list)\n",
    "\n",
    "for subject in subject_list:\n",
    "    subject_folder_path_left = os.path.join(save_folder_left, subject[7:-3])\n",
    "    subject_folder_path_right = os.path.join(save_folder_right, subject[7:-3])\n",
    "    os.makedirs(subject_folder_path_left, exist_ok=True)\n",
    "    os.makedirs(subject_folder_path_right, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject_data in subject_list:\n",
    "    csv_name = os.path.join(save_csv_folder, subject_data[7:-3] + '.csv')\n",
    "    print(csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_eth_eval_data(subject_data):\n",
    "\n",
    "    all_img_name_cnt = 1\n",
    "    gaze_datas = []\n",
    "    \n",
    "    global save_folder_right\n",
    "    global save_folder_left\n",
    "    global data_folder_path\n",
    "    global save_csv_folder\n",
    "\n",
    "    csv_name = os.path.join(save_csv_folder, subject_data[7:-3] + '.csv')\n",
    "    read_data_path = os.path.join(data_folder_path, subject_data)\n",
    "    fid = h5py.File(read_data_path, 'r')\n",
    "    img_size = 200\n",
    "    # img_show = np.zeros((img_size*3, img_size*6, 3), dtype=np.uint8)  # initial a empty image\n",
    "    gaze = []\n",
    "\n",
    "    for num_i in tqdm(range(fid[\"face_patch\"].shape[0])):\n",
    "        face_patch = fid['face_patch'][num_i]  # the face patch\n",
    "        # print(subject_data+' '+str(num_i))\n",
    "\n",
    "        if 'face_gaze' in fid.keys():\n",
    "            gaze = fid['face_gaze'][num_i]\n",
    "            # gaze = gaze_calc_show(gaze)\n",
    "            fid_path = read_data_path + str(num_i)\n",
    "            gaze_datas.append(gaze_calc(gaze, fid_path))\n",
    "\n",
    "            face_patch = cv2.resize(face_patch, (img_size, img_size)) #250x250\n",
    "            gray = cv2.cvtColor(face_patch, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            right_ldmks = []\n",
    "            left_ldmks = []\n",
    "            ldmks_list = []\n",
    "\n",
    "            with mp_face_mesh.FaceMesh(\n",
    "                static_image_mode=True,\n",
    "                max_num_faces=1,\n",
    "                refine_landmarks=True,\n",
    "                min_detection_confidence=0.5) as face_mesh:\n",
    "\n",
    "                image = face_patch\n",
    "                image_rows, image_cols, _ = image.shape\n",
    "                results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "                annotated_image = image.copy()\n",
    "\n",
    "                if results.multi_face_landmarks == None:\n",
    "\n",
    "                    right_ldmks_center = [60,90]\n",
    "                    left_ldmks_center = [130,90]\n",
    "                    save_img_right = img_cropper(gray, right_ldmks_center[0], right_ldmks_center[1])\n",
    "                    save_img_left = img_cropper(gray, left_ldmks_center[0], left_ldmks_center[1])\n",
    "\n",
    "                    save_img_name = str(all_img_name_cnt) + '.png'\n",
    "                    if save_img_right.shape[0] == 36 and save_img_right.shape[1] == 60:\n",
    "                        save_img_right_path = os.path.join(save_folder_right, subject_data[7:-3],  save_img_name)\n",
    "                        cv2.imwrite(save_img_right_path, save_img_right)\n",
    "\n",
    "                    else:\n",
    "                        sys.exit('Error Right Image')\n",
    "\n",
    "                    if save_img_left.shape[0] == 36 and save_img_left.shape[1] == 60:\n",
    "                        save_img_left_path = os.path.join(save_folder_left, subject_data[7:-3], save_img_name)\n",
    "                        cv2.imwrite(save_img_left_path, save_img_left)\n",
    "\n",
    "                    else:\n",
    "                        sys.exit('Error Left Image')\n",
    "\n",
    "                    all_img_name_cnt += 1\n",
    "\n",
    "                else:\n",
    "\n",
    "                    for face_landmarks in results.multi_face_landmarks:\n",
    "                        mp_drawing.draw_landmarks(\n",
    "                        image=annotated_image,\n",
    "                        landmark_list=face_landmarks,\n",
    "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                        landmark_drawing_spec=None,\n",
    "                        connection_drawing_spec=mp_drawing_styles\n",
    "                        .get_default_face_mesh_tesselation_style())\n",
    "\n",
    "                    for idx, landmark in enumerate(face_landmarks.landmark):\n",
    "                        if ((landmark.HasField('visibility') and\n",
    "                            landmark.visibility < _VISIBILITY_THRESHOLD) or \n",
    "                            (landmark.HasField('presence') and\n",
    "                            landmark.presence < _PRESENCE_THRESHOLD)):\n",
    "                            continue\n",
    "                        landmark_px = _normalized_to_pixel_coordinates(landmark.x, landmark.y,\n",
    "                                                                    image_cols, image_rows)\n",
    "\n",
    "                        if landmark_px is not None:\n",
    "                            ldmks_list.append(landmark_px)\n",
    "                        else:\n",
    "                            zero_coord = (0,0)\n",
    "                            ldmks_list.append(zero_coord)                                                \n",
    "                        # print(landmark_px)\n",
    "                        \n",
    "                    ldmks_array = np.array(ldmks_list)\n",
    "                    # print(ldmks_array.shape)\n",
    "\n",
    "                    if len(ldmks_array.shape) == 1:\n",
    "                        for r_num in right_list:\n",
    "                            if ldmks_array[r_num] != None:\n",
    "                                right_ldmks.append(ldmks_array[r_num])\n",
    "                        for l_num in left_list:\n",
    "                            if ldmks_array[l_num] != None:\n",
    "                                left_ldmks.append(ldmks_array[l_num])\n",
    "                    \n",
    "                    else:\n",
    "                        for r_num in right_list:\n",
    "                            if ldmks_array[r_num][0] != None:\n",
    "                                right_ldmks.append(ldmks_array[r_num])\n",
    "                        for l_num in left_list:\n",
    "                            if ldmks_array[l_num][0] != None:\n",
    "                                left_ldmks.append(ldmks_array[l_num])\n",
    "\n",
    "                    right_ldmks_center = np.mean(right_ldmks, axis=0)\n",
    "                    left_ldmks_center = np.mean(left_ldmks, axis=0)\n",
    "\n",
    "                    save_img_right = img_cropper(gray, right_ldmks_center[0], right_ldmks_center[1])\n",
    "                    save_img_left = img_cropper(gray, left_ldmks_center[0], left_ldmks_center[1])\n",
    "\n",
    "\n",
    "                    save_img_name = str(all_img_name_cnt) + '.png'\n",
    "                    if save_img_right.shape[0] == 36 and save_img_right.shape[1] == 60:\n",
    "                        save_img_right_path = os.path.join(save_folder_right, subject_data[7:-3], save_img_name)\n",
    "                        cv2.imwrite(save_img_right_path, save_img_right)\n",
    "\n",
    "                    else:\n",
    "                        sys.exit('Error Right Image')\n",
    "\n",
    "                    if save_img_left.shape[0] == 36 and save_img_left.shape[1] == 60:\n",
    "                        save_img_left_path = os.path.join(save_folder_left,subject_data[7:-3], save_img_name)\n",
    "                        cv2.imwrite(save_img_left_path, save_img_left)\n",
    "\n",
    "                    else:\n",
    "                        sys.exit('Error Left Image')\n",
    "\n",
    "                    all_img_name_cnt += 1\n",
    "\n",
    "    df_gaze = pd.DataFrame(gaze_datas)\n",
    "    df_gaze.to_csv(csv_name, index=False,header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = sorted(os.listdir(data_folder_path), key=lambda s: int(re.search(r'\\d+', s).group()))\n",
    "\n",
    "result = joblib.Parallel(n_jobs=-1,backend='threading')(joblib.delayed(split_eth_eval_data)(i) for i in subject_list)\n",
    "# result = joblib.Parallel(n_jobs=4)(joblib.delayed(split_eth_eval_data)(i) for i in subject_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('eth_env_2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a002989e48d358bd658a7b1d105faa7d9b0bee1ee973e01b961d1a5f0fef9825"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
